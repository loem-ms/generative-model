# A Journey of Generative Model

Generating illustrations or photorealistic images with natural language instructions is no longer surprising today. 
We can now generate high-quality images with many AI-based tools, such as DALL-E, Stable Diffusion, Midjourney, and many more. 
Technology that makes these possible is Generative Model, a technology that learns how data are generated and then generates new (pseudo) data that looks similar to the existing (human-generated) ones.
The following images are generated by ChatGPT.

![Introduction](./figures/intro.png)

In this article, we aim to walk you through the mathematical concept of the Generative Model, starting from **Normal Distribution**, stepping up to **Latent Variable Model** with **VAE** as a case study.
Finally, we will introduce **Diffusion Model**, a representative one that amazes the world with its realistic, high-quality image generation capability.

## Generative Model

The objective of a generative model is to represent (*modeling*) the distribution $p(x)$ of observed data $x$. Once the distribution $p(x)$ is obtained, new (pseudo) data can be generated (*sampling*) from that distribution.

![Figure 1](figures/fig1-modeling-sampling.png)

Ideally, if we could obtain the real distribution, we could easily generate new, accurate data. Unfortunately, in reality, it is impossible to get such real distribution. In such a scenario, we use some limited numbers of samples to estimate the real distribution. This can be implemented with the following two processes:

- **Modeling**: We assume that the real distribution can be approximated by a probabilistic distribution.
- **Parameter Estimation**: We adjust the parameters of that probabilistic distribution to make the distribution fit with the samples we have in hand. A method used for this estimation is Maximum Likelihood Estimation.

## Modeling
Modeling in generative models involves creating a mathematical representation of the data's distribution. This is critical as it allows the model to encapsulate the essential traits and variability of the data. Depending on the type and complexity of the data, the modeling approach varies significantly.

![Distributions](./figures/distributions.png)

#### Example with 1D Data: Normal Distribution
For one-dimensional (1D) data, a simple probabilistic model like the normal distribution can be effective. Consider a set of measurements that are centered around a specific value with a certain amount of random deviation (e.g., the heights of adult males). A normal distribution, defined by its mean ($\mu$) and variance ($\sigma^2$), can model this data efficiently. This approach is straightforward yet powerful in capturing the central tendency and dispersion of data.

#### Expanding to High-Dimensional Data: Images and Language
As the dimensionality and complexity of data increase, more sophisticated models are required. For image data, convolutional neural networks (CNNs) are typically used to model the spatial hierarchies and dependencies between pixels, capturing features from edges to complex objects within an image. In the case of sequential data such as text or time series, models like recurrent neural networks (RNNs) or transformers are employed. These models can handle temporal dynamics and long-range dependencies, making them suitable for tasks like language translation or speech recognition.

## Parameter Estimation
The process of parameter estimation involves fine-tuning the model's parameters so that it closely fits the data. Maximum Likelihood Estimation (MLE) is commonly used to achieve this by maximizing the likelihood function, indicating how likely the observed data is under the assumed model.

#### Example with 1D Data: Normal Distribution
For a normal distribution modeling 1D data, MLE would determine the mean and variance that maximize the likelihood of observing the sample data. This process involves calculating the average and the spread of the data points around that average, which are straightforward yet effective estimations of the parameters.

#### Expanding to High-Dimensional Data: Images and Language
In more complex scenarios, like images or language, the parameter estimation becomes more intricate. Techniques such as gradient descent are used to adjust the weights in neural networks. These techniques iteratively reduce the error between the model's predictions and the actual data, adjusting parameters like filter weights in CNNs or attention weights in transformers.
