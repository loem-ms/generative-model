{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score-based Diffusion Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous chapters, we have formulated generative model as probabilistic distribution $p(x)$ of observed data $x$.\n",
    "However, in reality, we may want to control the generative data with specific conditions $\\left(p(x|y)\\right)$ rather than in a random way.\n",
    "For example, we may want to generate an image of a cat in a specific pose, or a person in a particular hair style.\n",
    "Conditional diffusion models excel at this type of task, allowing us to steer the generative process towards desired outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we'll delve deeper into the inner workings of conditional diffusion models.\n",
    "We'll explore how they leverage the concept of score-based models and diffusion processes to achieve their impressive results.\n",
    "We'll also discuss some of the challenges and limitations of these models, and how researchers are working to address them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take conditions into account, we consider conditional diffusion model as the following conditional probabilistic distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "p_\\theta(x|y) &= \\int p_\\theta(x|x_1, y) \\cdots p_\\theta(x_{T-1}|x_T, y)p_\\theta(x_T)dx_1\\cdots dx_T \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous chapter, we have discussed the training method of denoising diffusion model with original data restoring or noise estimation with neural network decoder.\n",
    "In noise estimation, we use the noisy data and the corresponding time step as inputs of the neural network decoder.\n",
    "To extend this model to deal with conditions $y$, we need to revise the architecture of the decoder to consider the feature of the conditions during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Conditional Diffusion](../figures/chapter5/conditional_diffusion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There many ways for implementation.\n",
    "For example, a simple way is to consider the representation of conditions (this can be text, image, label, etc) as embedding vectors similar to the case of time step embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Embedding](../figures/chapter5/embedding.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
